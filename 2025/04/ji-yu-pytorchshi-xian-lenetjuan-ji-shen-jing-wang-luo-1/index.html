<!doctype html>
<html lang="en-US">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <title>梅岭随记 - 挪希的博客</title>
    <meta name="description" content="" />
    <meta name="Author" content="Vergica" />

    <!--[if lt IE 9]>
    <script type="text/javascript" src="http://stepofweb.gweb.io/.templates/IsisOne/HTML/assets/plugins/lt-ie9/html5.js"></script>
    <script type="text/javascript" src="http://stepofweb.gweb.io/.templates/IsisOne/HTML/assets/plugins/lt-ie9/respond.min.js"></script>
    <script type="text/javascript" src="http://stepofweb.gweb.io/.templates/IsisOne/HTML/assets/plugins/lt-ie9/excanvas.compiled.js"></script>
    <![endif]-->

    <!-- GOOGLE FONTS -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700,800|Dosis:300,400" rel="stylesheet" type="text/css" />


    <!-- CORE CSS FRAMEWORK -->
    <link href="//cdn.staticfile.net/twitter-bootstrap/3.1.0/css/bootstrap.min.css" rel="stylesheet" type="text/css" />
    <link href="//cdn.staticfile.net/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

    <!-- CSS TEMPLATE -->
    <link href="https://vergica.github.io/theme/css/reset.css" rel="stylesheet" type="text/css" />
    <link href="https://vergica.github.io/theme/css/framework.css" rel="stylesheet" type="text/css" />
    <link href="https://vergica.github.io/theme/css/typography.css" rel="stylesheet" type="text/css" />
    <link href="https://vergica.github.io/theme/css/layout.css" rel="stylesheet" type="text/css" />

    <link href="https://vergica.github.io/theme/css/blog.css" rel="stylesheet" type="text/css" />

    <!-- ICONS -->
        <link rel="shortcut icon" href="/theme/img/icon.jpg" type="image/x-icon" />
        <link rel="icon" href="/theme/img/icon.jpg" type="image/x-icon" />
        <link rel="shortcut icon" href="/theme/img/icon.jpg" type="image/x-icon" />

    <!-- mobile settings -->
    <meta name="viewport" content="width=device-width, maximum-scale=1, initial-scale=1, user-scalable=0" />

    <!-- Morenizr -->
    <script type="text/javascript" src="https://vergica.github.io/theme/js/modernizr.min.js"></script>

    <!-- google authorship -->
</head>
<body>

<!-- Main Nav -->
<header id="header" style="margin-top:0">

  <nav class="navbar navbar-inverse" role="navigation">
    <div class="container">

      <!-- Mobile Menu Button -->
      <button id="mobileMenu" class="fa fa-bars" type="button" data-toggle="collapse" data-target=".navbar-collapse"></button>

      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
<!--        <a class="navbar-brand scrollTo" href="#home">-->
        <a class="navbar-brand" href="https://vergica.github.io/index.html">
          <img src="/theme/img/icon.jpg" alt="" width="50" height="50" />
          <span class="hidden-xs">梅岭随记</span>
        </a>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">

        <!-- Fullscreen Button - Unavailable for IE -->
<!--        <a href="#" class="btn-fullscreen"><i class="fa fa-external-link"></i></a>-->

        <ul class="nav navbar-nav navbar-right">
          <!-- If the user wants to make articles the home page then remove blog link, and make about and work links point to old home page. -->
            <li><a href="https://vergica.github.io/index.html#home">Home</a></li>
            <li><a href="https://vergica.github.io/index.html#about">About</a></li>
            <li><a href="https://vergica.github.io/index.html#work">Work</a></li>
            <li><a href="https://vergica.github.io/blog.html">Blog</a></li>
        </ul>
      </div>
      <!-- /.navbar-collapse -->

    </div>
  </nav>
</header>
<!-- /Main Nav -->  <section id="blog">
    <article class="container">

      <div class="row">
        <div id="blog_main_area" class="left col-md-9">
  <!-- article title -->
  <header>
      <h1>基于PyTorch实现LeNet卷积神经网络（1）</h1>
    <small class="fsize13">
            <a href="https://vergica.github.io/category/ai.html" rel="tag tooltip" class="label label-default light" data-placement="right" data-original-title="1 article in this category"><i class="fa fa-dot-circle-o"></i> AI</a>
<!--      <a href="https://vergica.github.io/2025/04/ji-yu-pytorchshi-xian-lenetjuan-ji-shen-jing-wang-luo-1/#disqus_thread" class="scrollTo label label-default light" data-disqus-identifier="2025/04/ji-yu-pytorchshi-xian-lenetjuan-ji-shen-jing-wang-luo-1/"><i class="fa fa-comment-o"></i> ?? Comments</a>-->
      <span class="label label-default light">2025-04-25</span> 
    </small>
  </header>

  <article class='content'>
    <p>LeNet是早期的卷积神经网络之一，由两个卷积层和三个全连接层组成。本文采用PyTorch框架，分准备数据、构建网络、训练模型、测试效果四部分，详细介绍如何实现一个简单的LeNet网络，识别CIFAR-10数据集图片。</p>
<h4>准备数据</h4>
<p>本文训练及测试数据均来自<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10数据集</a>。<code>torchvision.datasets</code>模块提供了许多内置的数据库，其中就包括CIFAR-10，使用方法如下：</p>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="nl">root</span><span class="p">:</span><span class="w"> </span><span class="ow">Union</span><span class="o">[</span><span class="n">str, Path</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="nl">train</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">True</span><span class="p">,</span><span class="w"> </span><span class="nl">transform</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">Callable</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="nl">target_transform</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">Callable</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="nl">download</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">False</span><span class="p">)</span>
</code></pre></div>

<p>参数：</p>
<ul>
<li>root - 数据库的根目录，即<code>cifar-10-batches-py</code>所在的目录，若<code>cifar-10-batches-py</code>不存在且<code>download</code>为True时将保存在此。</li>
<li>train - 设置为True时，从训练集创建数据库，否则从测试集创建。</li>
<li>transform - 一个函数或transform（PyTorch提供的特殊成员，既可作为类，也可当作函数），接收一张PIL图片，返回其变换后的结果。</li>
<li>target_transform - 一个函数或transform，能接收并修改图片标签。</li>
<li>download - 设置为True时，将从官网下载数据集并保存到根目录。如果数据集已经被下载，则不会再次下载。</li>
</ul>
<p>在获取数据之后，需用调用<code>torch.utils.data.DataLoader</code>进行加载（比如指定分批的数量、取样的顺序、工作进程的数量等）。使用方法如下：</p>
<div class="highlight"><pre><span></span><code>torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=None, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=None, persistent_workers=False, pin_memory_device=&#39;&#39;, in_order=True)
</code></pre></div>

<p>参数：</p>
<ul>
<li>dataset - 用以加载数据的数据集。</li>
<li>batch_size - 每批数据加载的样本数量。</li>
<li>shuffle - 是否在每轮打乱数据。</li>
<li>sampler - 定义从数据集取样的方式（比如顺序或乱序等），与<code>shuffle</code>冲突。</li>
<li>batch_sampler - 与<code>sampler</code>类似，但每次返回一批索引，与<code>batch_size</code>，<code>shuffle</code>，<code>sampler</code>和<code>drop_last</code>冲突。</li>
<li>num_workers - 用于加载数据的子进程数量。若为0则表示将在主进程加载。</li>
<li>collate_fn - 将一系列样本合成为小批的张量，在分批读取映射式数据集时使用。（<code>DataLoader</code>可接收映射式数据集和可迭代式数据集，官方认为后者适用于随机读取开销大或批量大小取决于获取的数据的情况。）</li>
<li>pin_memory - 设置为True时，数据加载器会在返回张量前，将其拷贝到设备/CUDA的固定内存中。</li>
<li>drop_last - 若为True，在数据集大小不能被批量大小整除时，舍弃最后的不完整的批次。而为False时，若无法整除，则最后一批样本数量减少。</li>
<li>timeout - 若为正数，将限制从进程获取批量数据的时间。（应始终为非负数）</li>
<li>worker_init_fn - 如果不为<code>None</code>，这会在每个工作子进程中被调用，传递<code>worker id</code>（<code>[0, num_workers - 1]</code>中的整数）作为输入，发生在设置种子之后加载数据之前。</li>
<li>multiprocessing_context - 若值为<code>None</code>，则使用操作系统默认的多进程上下文（如<code>spawn</code>，<code>fork</code>或<code>forkserver</code>）。</li>
<li>generator - 若不为<code>None</code>，该RNG（随机数生成器）将被<code>RandomSampler</code>用于生成随机索引，并被多进程用于生成<code>base_seed</code>。</li>
<li>prefetch_factor - 每个进程中提前加载的批次的数量。若为2则说明共有2 * <code>num_workers</code>的批次预加载。</li>
<li>persistent_workers - 设置为<code>True</code>时，数据加载器将不会在数据集被使用后关闭工作进程。这能使数据集的实例保持激活。（这是官方的表述，有点抽象，大概用于提高模型训练效率。）</li>
<li>pin_memory_device - 数据加载器会在返回前将张量拷贝到设备的固定内存中（如果<code>pin_memory</code>为<code>True</code>）。</li>
<li>in_order - 如果设为<code>False</code>，则数据加载器不会强制批次以先进先出的顺序返回。只在<code>num_workers</code> &gt; 0时生效。</li>
</ul>
<p>虽然本文使用CIFAR-10数据库，图片均为32x32的相同格式彩图，但考虑到普遍情况下，数据集样本的格式存在差异，应当进行归一化处理。</p>
<p>完整代码如下：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="n">v2</span>
<span class="n">transform</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">v2</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="w">  </span><span class="c1"># Compose的作用为组合多个变换操作</span>
<span class="w">    </span><span class="n">v2</span><span class="o">.</span><span class="n">ToImage</span><span class="p">(),</span><span class="w">  </span><span class="c1"># 将张量/ndarray/PIL图片转化为Image格式，不缩放</span>
<span class="w">    </span><span class="n">v2</span><span class="o">.</span><span class="n">ToDtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span><span class="w">  </span><span class="c1"># 转化为float类型的张量，并进行缩放</span>
<span class="w">    </span><span class="n">v2</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">],</span><span class="w"> </span><span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">])</span><span class="w">  </span><span class="c1"># 用平均值和标准差对张量图像进行归一化处理，为了方便数值取0.5</span>
<span class="p">])</span>
<span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="w">  </span><span class="c1"># 每批数据的大小</span>
<span class="n">trainset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./dataset&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="w"> </span><span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="w"> </span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">trainloader</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span><span class="w"> </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="w"> </span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">testset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./dataset&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="w"> </span><span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="w"> </span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">testloader</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">testset</span><span class="p">,</span><span class="w"> </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="w"> </span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<h4>构建网络</h4>
<p>查询论文《<a href="https://ieeexplore.ieee.org/document/726791">Gradient-based learning applied to document recognition</a>》可知LeNet的具体结构如下：</p>
<p><img alt="LeNet的结构" src="https://raw.githubusercontent.com/vergica/images/main/%E5%9F%BA%E4%BA%8EPyTorch%E5%AE%9E%E7%8E%B0LeNet%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_1.png"></p>
<p>定义一个继承<code>torch.nn.Module</code>的类，并在子类中依次注册模块即可：</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="n">Model</span>(<span class="n">nn</span>.<span class="n">Module</span>):  <span class="c1"># nn.Module为所有神经网络模块的基类</span>
    <span class="n">def</span> <span class="n">__init__</span>(<span class="nb">self</span>):
        <span class="c1"># 执行父类的构造函数</span>
        <span class="n">super</span>().<span class="n">__init__</span>()
        <span class="c1"># 两层卷积层</span>
        <span class="nb">self</span>.<span class="n">conv1</span> = <span class="n">nn</span>.<span class="n">Conv2d</span>(<span class="mi">3</span>, <span class="mi">6</span>, <span class="mi">5</span>)
        <span class="nb">self</span>.<span class="n">conv2</span> = <span class="n">nn</span>.<span class="n">Conv2d</span>(<span class="mi">6</span>, <span class="mi">16</span>, <span class="mi">5</span>)
        <span class="c1"># 三层全连接层</span>
        <span class="nb">self</span>.<span class="n">fc1</span> = <span class="n">nn</span>.<span class="n">Linear</span>(<span class="mi">400</span>, <span class="mi">120</span>)
        <span class="nb">self</span>.<span class="n">fc2</span> = <span class="n">nn</span>.<span class="n">Linear</span>(<span class="mi">120</span>, <span class="mi">84</span>)
        <span class="nb">self</span>.<span class="n">fc3</span> = <span class="n">nn</span>.<span class="n">Linear</span>(<span class="mi">84</span>, <span class="mi">10</span>)

    <span class="n">def</span> <span class="n">forward</span>(<span class="nb">self</span>, <span class="nb">x</span>):
        <span class="c1"># 卷积 -&gt; 激活 -&gt; 池化</span>
        <span class="c1"># 论文使用了sigmoid作为激活函数，但事实上ReLU函数效果更好</span>
        <span class="c1"># 池化层核大小为2x2，参数可写作2，也可写作(2, 2)</span>
        <span class="c1"># [batch size, 3, 32, 32] -- conv1 --&gt; [batch size, 6, 28, 28] -- avg_pool --&gt; [batch size, 6, 14, 14]</span>
        <span class="nb">x</span> = <span class="n">F</span>.<span class="n">avg_pool2d</span>(<span class="n">F</span>.<span class="n">relu</span>(<span class="nb">self</span>.<span class="n">conv1</span>(<span class="nb">x</span>)), <span class="mi">2</span>)
        <span class="c1"># [batch size, 6, 14, 14] -- conv2 --&gt; [batch size, 16, 10, 10] -- avg_pool --&gt; [batch size, 16, 5, 5]</span>
        <span class="nb">x</span> = <span class="n">F</span>.<span class="n">avg_pool2d</span>(<span class="n">F</span>.<span class="n">relu</span>(<span class="nb">self</span>.<span class="n">conv2</span>(<span class="nb">x</span>)), <span class="mi">2</span>)
        <span class="c1"># 把 16 * 5 * 5 的特征图展平，变为[batch size, 16 * 5 * 5]，以送入全连接层</span>
        <span class="nb">x</span> = <span class="nb">x</span>.<span class="n">view</span>(<span class="nb">x</span>.<span class="n">size</span>()[<span class="mi">0</span>], -<span class="mi">1</span>)
        <span class="c1"># [batch size, 400] -- fc1 --&gt; [batch size, 120]</span>
        <span class="nb">x</span> = <span class="n">F</span>.<span class="n">relu</span>(<span class="nb">self</span>.<span class="n">fc1</span>(<span class="nb">x</span>))
        <span class="c1"># [batch size, 120] -- fc2 --&gt; [batch size, 84]</span>
        <span class="nb">x</span> = <span class="n">F</span>.<span class="n">relu</span>(<span class="nb">self</span>.<span class="n">fc2</span>(<span class="nb">x</span>))
        <span class="c1"># [batch size, 84] -- fc3 --&gt; [batch size, 10]</span>
        <span class="nb">x</span> = <span class="n">F</span>.<span class="n">relu</span>(<span class="nb">self</span>.<span class="n">fc3</span>(<span class="nb">x</span>))
        <span class="k">return</span> <span class="nb">x</span>
</code></pre></div>

<p>代码中涉及的<code>nn.Conv2d</code>，<code>nn.Linear</code>，<code>F.relu</code>，<code>F.avg_pool2d</code>并不难理解，可查看官方文档的<a href="https://pytorch.org/docs/stable/nn.html">torch.nn</a>和<a href="https://pytorch.org/docs/stable/nn.functional.html">nn.functional</a>了解详细用法。</p>
  </article>

  <div class="divider"><!-- lines divider --></div>

  <!-- SOCIAL -->
<p class="socials">
    <a href="http://www.facebook.com/sharer/sharer.php?u=https://vergica.github.io/2025/04/ji-yu-pytorchshi-xian-lenetjuan-ji-shen-jing-wang-luo-1/" class="rounded-icon social fa fa-facebook" target="_blank" title="Share on Facebook"><!-- facebook --></a>
    <a href="http://twitter.com/home?status=https://vergica.github.io/2025/04/ji-yu-pytorchshi-xian-lenetjuan-ji-shen-jing-wang-luo-1/" class="rounded-icon social fa fa-twitter" target="_blank" title="Share on Twitter"><!-- twitter --></a>
    <a href="https://plus.google.com/share?url=https://vergica.github.io/2025/04/ji-yu-pytorchshi-xian-lenetjuan-ji-shen-jing-wang-luo-1/" class="rounded-icon social fa fa-google-plus" target="_blank" title="Share on Google+"><!-- google plus --></a>
    <a href="http://pinterest.com/pin/create/link/?url==https://vergica.github.io/2025/04/ji-yu-pytorchshi-xian-lenetjuan-ji-shen-jing-wang-luo-1/" class="rounded-icon social fa fa-pinterest"  target="_blank" title="Share on Pinterest"><!-- pinterest --></a>
    <a href="http://www.linkedin.com/shareArticle?mini=true&url=https://vergica.github.io/2025/04/ji-yu-pytorchshi-xian-lenetjuan-ji-shen-jing-wang-luo-1/&title=基于PyTorch实现LeNet卷积神经网络（1）&summary=&source=" class="rounded-icon social fa fa-linkedin" target="_blank" title="Share on Linkedin"><!-- linkedin --></a>
</p>  

  <!-- TAGS -->
  <p class="fsize16"> Tags:
        <a href="/tag/pytorch.html" rel="tooltip" class="label label-default light" data-placement="right" data-original-title="1 article with this tag"><i class="fa fa-tags"></i> PyTorch</a>
        <a href="/tag/lenet.html" rel="tooltip" class="label label-default light" data-placement="right" data-original-title="1 article with this tag"><i class="fa fa-tags"></i> LeNet</a>
  </p>

  <hr /><!-- divider -->

        </div>

        <!-- SIDEBAR -->
        <div class="right col-md-3">
          <!-- recent work -->
          <!-- <div class="widget">

                      <h3>Recent Work</h3>

                      <a class="popup-image thumb" href="assets/images/preview/slider/1.jpg">
                          <img src="https://vergica.github.io/theme/img/1x1.png" class="img-responsive" data-src="holder.js/85x85/#888:#555555/auto/" alt="img" />
                      </a>
                      <a class="popup-video thumb" href="http://www.youtube.com/watch?v=kh29_SERH0Y?rel=0">
                          <img src="https://vergica.github.io/theme/img/1x1.png" class="ajax-project img-responsive" data-src="holder.js/85x85/#676767:#555555/auto/" alt="img" />
                      </a>
                      <a class="popup-video thumb" href="http://vimeo.com/23630702">
                          <img src="https://vergica.github.io/theme/img/1x1.png" class="ajax-project img-responsive" data-src="holder.js/85x85/#888:#555555/auto/" alt="img" />
                      </a>

                      <a class="external ajax-project thumb" href="project-external-1.html">
                          <img src="https://vergica.github.io/theme/img/1x1.png" class="ajax-project img-responsive" data-src="holder.js/85x85/#676767:#555555/auto/" alt="img" />
                      </a>
                      <a class="external ajax-project thumb" href="project-external-2.html">
                          <img src="https://vergica.github.io/theme/img/1x1.png" class="ajax-project img-responsive" data-src="holder.js/85x85/#888:#555555/auto/" alt="img" />
                      </a>
                      <a class="external ajax-project thumb" href="project-external-3.html">
                          <img src="https://vergica.github.io/theme/img/1x1.png" class="ajax-project img-responsive" data-src="holder.js/85x85/#676767:#555555/auto/" alt="img" />
                      </a>

                      <div class="clearfix"></div>
                  </div> -->

          <!-- categories -->
          <div class="widget">

            <h3>Categories</h3>

            <ul>
               <li><a class="theme_link" href="https://vergica.github.io/category/ai.html"><i class="fa fa-dot-circle-o"></i> AI</a>
              </li>
              <li><a class="theme_link" href="https://vergica.github.io/category/python.html"><i class="fa fa-dot-circle-o"></i> Python</a>
              </li>
            </ul>

          </div>

          <!-- Archives -->
          <div class="widget">

            <h3>Archives</h3>

            <!-- Get all of the articles with their dates -->
            <div class="hidden">
                None
                None
                None
            </div>

            <!-- If the user indicates they prefer a list.-->                <ul class="tree">
                    <li>
                        <span><i class="fa fa-minus-square-o"></i>2025</span>
                        <ul>
                            <li>
                                <span><i class="fa fa-plus-square-o"></i>2025-04</span>
                                <ul>
                                        <li style="display: none;">
                                            <a class="theme_link" href="https://vergica.github.io/2025/04/ji-yu-pytorchshi-xian-lenetjuan-ji-shen-jing-wang-luo-1/">
                                            <small>2025-04-25</small>基于PyTorch实现LeNet卷积神经网络（1）</a>
                                        </li>
                                </ul>
                            </li>
                        </ul>                        <span><i class="fa fa-minus-square-o"></i>2024</span>
                        <ul>
                            <li>
                                <span><i class="fa fa-plus-square-o"></i>2024-08</span>
                                <ul>
                                        <li style="display: none;">
                                            <a class="theme_link" href="https://vergica.github.io/2024/08/geng-huan-bo-ke-zhu-ti-he-xiang-ying-pei-zhi/">
                                            <small>2024-08-15</small>更换博客主题和相应配置</a>
                                        </li>
                                        <li style="display: none;">
                                            <a class="theme_link" href="https://vergica.github.io/2024/08/windowsxi-tong-xia-shi-yong-pelican-github-pagesbu-shu-ge-ren-bo-ke/">
                                            <small>2024-08-15</small>Windows系统下使用Pelican + GitHub Pages部署个人博客</a>
                                        </li>
                                </ul>
                            </li>
                        </ul></li>
                </ul></div>

        </div>
        <!-- /SIDEBAR -->

      </div>

    </article>
  </section>
  <!-- /BLOG -->

<!-- FOOTER -->
<footer>

  <!-- SCROOL TO TOP -->
<!--  <a href="#toTop" class="fa fa-arrow-up toTop"></a>-->

  <div class="container">

    <div class="row">

        <div class="col-md-6 copyright">
            梅岭随记
            <br />2024 &copy; All Rights Reserved.
        </div>

        <div class="col-md-6 text-right">
        </div>

    </div>

  </div>
</footer>
<!-- /FOOTER -->



<!-- CORE FILES -->
<script type="text/javascript" src="//cdn.staticfile.net/jquery/1.10.2/jquery.min.js"></script>
<script type="text/javascript" src="//cdn.staticfile.net/twitter-bootstrap/3.1.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/jquery.isotope.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/masonry.js"></script>

<!-- PLUGINS -->
<script type="text/javascript" src="https://vergica.github.io/theme/js/jquery.fitvids.min.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/jquery.appear.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/jquery.superslides.min.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/owl.carousel.min.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/jquery.carouFredSel-6.2.1-packed.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/jquery.countTo.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/jquery.magnific-popup.min.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/holder.js"></script>
<!-- delete on production -->

<!-- js scripts -->
<script async type="text/javascript" src="https://vergica.github.io/theme/js/scripts.js"></script>

<script type="text/javascript" src="https://vergica.github.io/theme/js/ImageAutoResize.js"></script>
<script type="text/javascript" src="https://vergica.github.io/theme/js/application.js"></script>





</body>

</html>